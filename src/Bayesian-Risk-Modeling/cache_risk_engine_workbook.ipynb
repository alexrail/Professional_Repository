{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bcdd33a5",
   "metadata": {},
   "source": [
    "# Real-Time Bayesian Risk Engine (Cache-Based Workflow)\n",
    "\n",
    "This workbook illustrates a **production-style** Python workflow for real-time Bayesian updating of\n",
    "segment-level recovery probabilities using a cache (e.g., Redis). It mirrors the type of logic\n",
    "you might use at a place like Veuu or Divine, but runs locally with an in-memory mock cache.\n",
    "\n",
    "- We define a small event schema (repayments/defaults).\n",
    "- We use a cache-like interface to store posterior parameters `(alpha, beta)` per segment.\n",
    "- We implement a `BayesianRiskEngine` that updates posteriors as events arrive.\n",
    "- We simulate daily claim data over time and plot posterior evolution.\n",
    "\n",
    "In production, the cache would be a service like Redis or AWS ElastiCache; here we use a simple\n",
    "Python dictionary to keep things self-contained and readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efdd4b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "from typing import Dict, List\n",
    "\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1163113b",
   "metadata": {},
   "source": [
    "## Event Schema\n",
    "We define a simple repayment event to simulate incoming claim outcomes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1787ee99",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class RepaymentEvent:\n",
    "    segment_id: str  # e.g., insurer, provider group, or region\n",
    "    recovered: int   # 1 = recovered, 0 = default\n",
    "    amount: float    # claim amount (not strictly needed for the posterior, but realistic)\n",
    "    timestamp: str   # ISO-like timestamp string for illustration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4042e679",
   "metadata": {},
   "source": [
    "## Cache Interface (Mock Redis)\n",
    "In production this would talk to Redis/ElastiCache. Here we simulate it with an in-memory dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87a8f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CacheInterface:\n",
    "    def get(self, key: str):\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def set(self, key: str, value):\n",
    "        raise NotImplementedError\n",
    "\n",
    "\n",
    "class InMemoryCache(CacheInterface):\n",
    "    def __init__(self):\n",
    "        self.store: Dict[str, dict] = {}\n",
    "\n",
    "    def get(self, key: str):\n",
    "        return self.store.get(key)\n",
    "\n",
    "    def set(self, key: str, value):\n",
    "        self.store[key] = value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc488d7",
   "metadata": {},
   "source": [
    "## Bayesian Risk Engine\n",
    "`BayesianRiskEngine` encapsulates the Bayesian updating logic and cache interaction.\n",
    "\n",
    "- Each `segment_id` has a Beta prior/posterior `(alpha, beta)`.\n",
    "- We update `(alpha, beta)` as new events arrive.\n",
    "- We can query the posterior mean recovery probability for any segment.\n",
    "\n",
    "In a real app, this class lives in a service that is called on each repayment/default event."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b1d99d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianRiskEngine:\n",
    "    def __init__(self, cache: CacheInterface, prior_alpha: float = 2.0, prior_beta: float = 2.0):\n",
    "        self.cache = cache\n",
    "        self.prior_alpha = prior_alpha\n",
    "        self.prior_beta = prior_beta\n",
    "\n",
    "    def _cache_key(self, segment_id: str) -> str:\n",
    "        return f\"segment:{segment_id}:beta_params\"\n",
    "\n",
    "    def _get_params(self, segment_id: str):\n",
    "        key = self._cache_key(segment_id)\n",
    "        record = self.cache.get(key)\n",
    "        if record is None:\n",
    "            return self.prior_alpha, self.prior_beta\n",
    "        return record[\"alpha\"], record[\"beta\"]\n",
    "\n",
    "    def _set_params(self, segment_id: str, alpha: float, beta: float):\n",
    "        key = self._cache_key(segment_id)\n",
    "        self.cache.set(key, {\"alpha\": alpha, \"beta\": beta})\n",
    "\n",
    "    def update_segment_batch(self, segment_id: str, recoveries: np.ndarray):\n",
    "        alpha, beta = self._get_params(segment_id)\n",
    "        alpha_new = alpha + int(np.sum(recoveries))\n",
    "        beta_new = beta + len(recoveries) - int(np.sum(recoveries))\n",
    "        self._set_params(segment_id, alpha_new, beta_new)\n",
    "        return alpha_new, beta_new\n",
    "\n",
    "    def update_segment_event(self, event: RepaymentEvent):\n",
    "        recoveries = np.array([event.recovered])\n",
    "        return self.update_segment_batch(event.segment_id, recoveries)\n",
    "\n",
    "    def get_posterior_mean(self, segment_id: str) -> float:\n",
    "        alpha, beta = self._get_params(segment_id)\n",
    "        return alpha / (alpha + beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc995715",
   "metadata": {},
   "source": [
    "## Simulation Harness (Production-Style Flow)\n",
    "We now simulate an environment where multiple segments receive claim outcomes day after day.\n",
    "\n",
    "- In production, events would be coming from a queue or stream (e.g., Kafka, Kinesis).\n",
    "- Here, we simply generate synthetic events and feed them through the `BayesianRiskEngine`.\n",
    "- We track posterior means over time for each segment.\n",
    "\n",
    "Note: you could imagine this loop running inside a background worker or microservice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b383d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_year(engine: BayesianRiskEngine, days: int = 60):\n",
    "    segments = [\"SEG_A\", \"SEG_B\", \"SEG_C\"]\n",
    "    true_rates = {\"SEG_A\": 0.60, \"SEG_B\": 0.50, \"SEG_C\": 0.70}\n",
    "    claims_per_day = 500  # conceptually thousands; kept smaller for runtime\n",
    "\n",
    "    history = {seg: [] for seg in segments}\n",
    "\n",
    "    for day in range(days):\n",
    "        for seg in segments:\n",
    "            recoveries = np.random.binomial(1, true_rates[seg], size=claims_per_day)\n",
    "            engine.update_segment_batch(seg, recoveries)\n",
    "            mean = engine.get_posterior_mean(seg)\n",
    "            history[seg].append(mean)\n",
    "\n",
    "    return history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbaff27",
   "metadata": {},
   "source": [
    "### Run the Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ab8272",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = InMemoryCache()\n",
    "engine = BayesianRiskEngine(cache, prior_alpha=2.0, prior_beta=2.0)\n",
    "posterior_history = simulate_year(engine, days=60)\n",
    "posterior_history['SEG_A'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "811b22d2",
   "metadata": {},
   "source": [
    "## Plot Posterior Evolution by Segment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb150ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "days = range(1, len(next(iter(posterior_history.values()))) + 1)\n",
    "true_rates = {\"SEG_A\": 0.60, \"SEG_B\": 0.50, \"SEG_C\": 0.70}\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "for seg, means in posterior_history.items():\n",
    "    plt.plot(days, means, label=f\"{seg} (true={true_rates[seg]:.2f})\")\n",
    "\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Posterior Mean Recovery Probability')\n",
    "plt.title('Evolution of Posterior Means by Segment')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle=':')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f07271fa",
   "metadata": {},
   "source": [
    "## How This Maps to a Production Environment\n",
    "\n",
    "In a real system (e.g., Veuu or Divine):\n",
    "\n",
    "- `InMemoryCache` would be replaced by a Redis/ElastiCache client.\n",
    "- `update_segment_event` would be called by a service that consumes repayment/default events from a queue/stream.\n",
    "- Periodic jobs could snapshot cache values to a persistent database for analytics and backtesting.\n",
    "- Thompson Sampling or other decision logic could call `get_posterior_mean` (or sample from the Beta distribution)\n",
    "  to drive dynamic credit limits, pricing, or allocation.\n",
    "\n",
    "Here, we keep everything local and simple, but the structure (event → cache read → Bayesian update → cache write)\n",
    "matches what you would do in production."
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
